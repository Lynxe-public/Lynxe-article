我认为，不是 Dify 和 Coze 不能用，也不是它们做得不好，而是我越来越觉得：这些工具的上限太低，不适合在真正的业务场景去持续使用。

我记得去年刚接触 Coze，Dify 的时候感觉很新奇，不用写代码，拖几个节点就能做个聊天机器人，还能接知识库、调插件，这确实是可以很大的提效。界面清晰，支持自托管，我们团队还拿它做过好几个内部 AI 工具原型。那会儿真觉得，"低代码 + 大模型"是条明路。

但问题是，用着用着就会发现瓶颈。不是工具本身的问题，而是当我遇到那些"无法提前想清楚"的场景时，Workflow 的局限性就暴露出来了。

比如我想做个能自动分析竞品动态、整理成周报的助手。听起来很简单，但在 Workflow 里实现起来特别别扭：我得提前想好每一步怎么走，什么条件下跳转，数据怎么传……一旦中间某个 API 失败或者输入格式变了，整个流程就崩了。更致命的是，很多场景我根本没办法提前把所有情况都想清楚。

就拿竞品分析这个场景来说，问题更具体：我需要监控的竞品可能有十几个，每个竞品的信息来源又完全不同——有些在官网的"产品更新"页面，有些在 GitHub/Gitee 的 Releases，有些在知乎、CSDN、掘金的技术文章，还有些在微博、小红书的产品动态。更麻烦的是，每个页面的 HTML 结构都不一样：官网可能是 `<div class="update-item">`，GitHub 是 `<div class="release">`，知乎是 `<div class="ContentItem">`，CSDN 是 `<article class="blog-item-box">`，微博又是完全不同的结构。

在 Workflow 里，我只能这样设计：

开始 -> 爬取竞品A官网 -> 解析HTML结构A -> 提取信息 
      -> 爬取竞品B GitHub -> 解析HTML结构B -> 提取信息
      -> 爬取竞品C 知乎 -> 解析HTML结构C -> 提取信息
      -> 爬取竞品D 微博 -> 解析HTML结构D -> 提取信息
      -> ... (每个网站都要重复做一次)
      -> 汇总数据 -> 生成报告


但现实是：
- 今天竞品 A 官网改版了，HTML 结构变了，整个解析节点就失效了
- 明天发现竞品 D 的信息在脉脉上，我又得加新节点
- 后天竞品 E 的页面加了反爬虫验证码，需要特殊处理
- 而且我根本不知道未来还会出现什么新的信息源

**我永远无法穷举所有可能的情况**。每增加一个竞品、每遇到一个新的页面结构，都要重新设计流程、写解析逻辑、测试、上线。这哪是"低代码"？这分明是在用图形界面写死代码。

所以小结一下：

Coze、Dify 这类 Workflow 平台，本质上还是人在做决策，AI 只是执行器。它们解决的是"如何更快地拼出一个 bot"，而不是"如何让 AI 真正帮我解决问题"。

从本质来说，Workflow 与传统编程模型其实很相似——都是程序控制的流程流转，都需要提前设计好所有逻辑。它们的区别只在于：传统编程用代码写死流程，Workflow 用图形界面拖拽流程。但核心问题没变：**我永远无法穷举所有可能的情况**。

而 Agent 的玩法则完全不同。它的决策权完全下放给了 AI，能够解决原有写程序不能解决的问题——比如处理不确定性、动态调整策略、理解自然语言意图等。就像竞品分析那个例子，Agent 不需要我提前设计好所有页面结构，它会自己探索、适应、调整。

所以我的看法是：
- **如果我只是想快速做个 MVP、内部小工具、FAQ 客服之类的东西**，Coze 和 Dify 依然很好用，省时省力。
- **但如果我想做点真正有差异化的、智能感强的产品，或者我的场景本身就充满不确定性**——比如研究分析、复杂任务编排、个性化服务——那真的该看看 Agent 的世界了。

关键是要理解每种方式的本质。Agent 的核心价值在于它开辟了新的可能性，让 AI 真正成为决策者，而不仅仅是执行者。这才是我们真正需要的"AI 助手"。

---

最近在知乎上看到不少人在讨论 Agent、传统编程和工作流（Workflow）的区别，也看到很多人在问"为什么 Coze、Dify 这类工具好像没那么火了"。

如果你也想深入了解这三者的本质差异，可以看看我之前写的[《深入了解智能体工作流核心：Agent vs 传统编程 vs Workflow 的本质区别》](https://zhuanlan.zhihu.com/p/1987101754261780132)。那篇文章通过对比表格和具体例子，尝试说清楚三者的核心差异，以及什么时候该用哪种方式。期望能帮你更好地判断场景，选择合适的技术方案。欢迎交流讨论~


